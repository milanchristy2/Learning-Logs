Computer Science concepts


Computer-> a piece of tape that holds ones and zeros along with a device that can read and write to it
it is called a turning machine 
Turning Machine-> it can compute anything in theory 
Central Processing Unit(core of the computer)->made of a piece of silicon that contains billions of transistors
Transistors->microspoic on and off switch and the value at one of these switches 
BIT->smallest piece of information a computer can use
BYTE->one byte can represent 256 different values
ASCII Character Encoding->when keys are pressed on the keyboard the character produced is actually mapped to a binary value 
in a character encoding like ascii or utf-8
Binary-> a system for counting like base-10 when counting on your fingers
Hexadecimal base-16 format->10 numbers and 6 letters can represent a four bit called a nibble
Nibble-> four bit digit
Machine Code->binary format which can be decoded and executed by the cpu
RAM->it is used to store data for the applications 
Memory Address-> in which cpu can read and write too
Input/Output->input device(keyboard and mouse) and output device(monitor)
Operating System kernals-> like windows,macos and linux that control all hardware resources via device
drivers
Shell->program that exposes the operating system to the end user it wraps the kernel
Command Line interface->not only connect to your own computer but with secure shell protocol
SSL-> it connect with remote computers over the network
Mainframe->bulk data processing computer 
Progamming Language->a tool that uses abstarction principle 
Abstraction Principle->to make computers practical work with humans by simplying different systems layer
by layer
Interpreted-> a program that executes the code line by line(interpreter)
Compiled->  a program that converts the source code into machine code in advance before the cpu attempts to 
excute it
Executable File->that can be run by the operating system without any extra dependencies  
Data Types->to represent data in the code
Variable->a container that can be reuse some else in your code
Dynamically typed language->we don't need a program to tell which data type is assigned to a variable
Statically typed->specify the data type of a variable in the code
Pointer-> a variable whose value is memory address of another variable which can be used for low-level memory control
Garbage Collector->which automatically allocates and deallocates the memory when an object is no longer
referenced in the program 
Int-> typically used to represent whole numbers which may or maybe not be signed 
Signed or Unsigned-> to represent negative numbers 
Float->there is enough memory to represent a certain  range of numbers at a certain position 
basically like a form of scientific notation to make computers faster
Double->that doubles the amount of memory used for number
Char->represnets a character data type
String->represnets multiple characters together
Big Endian->the memory stored in order with the most significant byte and smallest memory address
Little Endina->least significant byte stored in smallest memory address
Data Structures-> they are essential 
Array or List->like a shopping list that  organizes multiple data points in order which maintains an index
starting from zero and goes all the way up for every new item in list or array
Linked List->where each item will have a pointer to the next item in front of it
Stack->last in first out principle stacking a set of plates    
Queue->first in first out principle
Hash-> which can be called array list or dictionary it gives a collection of key-value pairs
Trees->organizes nodes in a hierachy that can be often traverse quickly it rigid through
Graph->to connect multiple nodes together in a virutally unlimited number of ways
node for data and edge for a relationship between data points 
Algorithm->a code that solves a problem
Function-> a block of code that takes an input and does something and returns an output 
Arguments-> input parameters
Operators
Boolean Data type-> true or false
Statement-> code doing something which handles conditional logic
Conditional logic-> if condition is true execute this code otherwise short circuit  and run the code inside of the
else block
While loop-> run the statement again and again until the condition inside the parenetheses becomes false
Iterable-> like a for loop that can run some code for every object in an array or Iterable data Structure
For loop 
Void-> no return value
Recursion-> a funciton calling iteself
Call Stack->a short term memory for executing the code
Stack Overflow error
to aviod this the algo needs a base case
Big-O notation-> standarad format for approximating   the Performance of an algorithm at scale
Time Complexity-> how fast your alogirthm runs  
Space Complexity->which deals   with how much memory required to run it
Brute Force approach->possible combinations to solve a particular problem
Divide and Conquer-> like binary search
Dynamic Programming->where a problem is broken down into multiple sub problems and 
result of each computation is stored for later use
Memoization-> if a function is alraedy been called it will use the existing value instead of recomputing
from scratch
Greedy algo-> that will make a choice  that is benefical in the short term without considering the problem as whole
Dijkstra's Shortest Path->
Backtracking-> taking a more incremental apporach by looking at all possible options like a rat in the 
maze exploring all diffrenet options
Declarative->code describes what your program does and the outcome but does not care about the 
control flow
Functional languages-> uses Declarative style like hashkell
Imperative->using statement like if and while providing explicit instructions to provide an outcome
Procedural languages-> imperative style like c
Multiparadigm languages->like python js swift kotlin support all these options at the same time
Object Oritened Programming-> 
class property methods inheritance design patterns 
instantiate objects which are chunks of data living inside your memory
Heap->unlike the call stack  can grow and shrink based on your application it allows you to pass
objects as reference which can use sample object in multiple varaibles withtout increasing the memory
footprint
Threads->takes the physical cpu core and breaks into virtual cores that allows you to run the code
simultaneously  
Parallelism->where the code is executed on 2-3 different threads at the same time
Concurrency->like an event-loop coroutines that can pause or delay normal execution code to handle
mutliple jobs on a single thread  at the same time
Bare metal cpu in ram->
Virtual Machine
Ip address
URL
Domain Name system
Tcp handshake
Packets 
Secure sokcets layer
HTTP
Application Programming Interface 
Printers



Rest - > simple stateless follows 
1. What is REST?
REST (Representational State Transfer) is an API architectural style used to design web services.
In REST:
Everything is treated as a resource
Resources are identified using URLs
Communication happens over HTTP
Data is usually exchanged in JSON
Example

https://api.example.com/users/101

2. Key Principles of REST
Client–Server Architecture
Client and server are separate; they communicate via requests and responses.
Statelessness
Each request contains all the information needed.
The server does not store client state.
Uniform Interface
Standard HTTP methods are used.
Resource-Based
Data is accessed via resource identifiers (URIs).
Cacheable
Responses can be cached to improve performance.

REST HTTP Methods and Their Components
Each REST method consists of components:
HTTP Method
URL (Endpoint)
Headers
Request Body (if applicable)
Response

1. GET – Retrieve Data
Used to fetch data from the server.
Components
Method: GET
URL: /users/101
Headers: Authorization, Content-Type
Body: ❌ Not used
Response: Data + status code

Example
GET /users/101
Common Status Codes
200 OK
404 Not Found


2. POST – Create New Resource
Used to send data to the server to create a new resource.
Components
Method: POST
URL: /users
Headers: Content-Type, Authorization
Body: Data to create resource
Response: Created resource
Example


Example
POST /users
{
  "name": "Alice",
  "email": "alice@example.com"
}
Common Status Codes
201 Created
400 Bad Request

3. PUT – Update Entire Resource
Used to replace an existing resource completely.
Components
Method: PUT
URL: /users/101
Headers: Content-Type
Body: Complete updated data
Response: Updated resource
Example
PUT /users/101
{
  "name": "Alice Smith",
  "email": "alice.smith@example.com"
}
Common Status Codes
200 OK
204 No Content

4. PATCH – Update Partial Resource
Used to update part of a resource.
Components
Method: PATCH
URL: /users/101
Headers: Content-Type
Body: Only fields to change
Response: Updated resource
Example
PATCH /users/101
{
  "email": "newemail@example.com"
}
Common Status Codes
200 OK

5. DELETE – Remove Resource
Used to delete a resource.
Components
Method: DELETE
URL: /users/101
Headers: Authorization
Body: ❌ Usually not used
Response: Confirmation
Example
DELETE /users/101
Common Status Codes
Common Status Codes
200 OK
204 No Content

| Method | Purpose     | Request Body | Example      |
| ------ | ----------- | ------------ | ------------ |
| GET    | Read data   | ❌ No         | Get user     |
| POST   | Create data | ✅ Yes        | Add user     |
| PUT    | Update all  | ✅ Yes        | Replace user |
| PATCH  | Update part | ✅ Yes        | Modify user  |
| DELETE | Delete data | ❌ No         | Remove user  |




5. REST Request–Response Components (Exam-Friendly)
Request Components
HTTP Method
URL / Endpoint
Headers
Body (optional)
Response Components
Status Code
Headers
Response Body




POST /users HTTP/1.1
Host: api.example.com
Content-Type: application/json

{
  "name": "John"
}

Concurrency vs Parallelism

| Feature          | Concurrency                 | Parallelism                |
| ---------------- | --------------------------- | -------------------------- |
| Meaning          | Managing many tasks at once | Running many tasks at once |
| Execution        | Tasks overlap in time       | Tasks run simultaneously   |
| CPU cores needed | Single or multiple          | Multiple required          |
| Focus            | Structure & design          | Performance & speed        |
| Switching        | Context switching           | No switching               |
| Best for         | I/O-bound tasks             | CPU-bound tasks            |
| Example          | Async API requests          | Multi-core data processing |


Components 

URL ENDPOINT 
Headers
Request Body
Response




| HTTP Method | Purpose                   | Used For                 | Request Body | Idempotent* | Example                |
| ----------- | ------------------------- | ------------------------ | ------------ | ----------- | ---------------------- |
| **GET**     | Retrieve data from server | Reading a resource       | ❌ No         | ✅ Yes       | Get user details       |
| **POST**    | Send data to server       | Creating a new resource  | ✅ Yes        | ❌ No        | Create new user        |
| **PUT**     | Replace existing resource | Updating entire resource | ✅ Yes        | ✅ Yes       | Update user completely |
| **PATCH**   | Modify part of a resource | Partial update           | ✅ Yes        | ❌ No        | Update email only      |
| **DELETE**  | Remove a resource         | Deleting data            | ❌ No         | ✅ Yes       | Delete user            |
| **HEAD**    | Retrieve headers only     | Check resource existence | ❌ No         | ✅ Yes       | Check if file exists   |
| **OPTIONS** | Get allowed methods       | CORS & API discovery     | ❌ No         | ✅ Yes       | Allowed API methods    |
| **TRACE**   | Echo request              | Debugging                | ❌ No         | ❌ No        | Test request path      |
| **CONNECT** | Create tunnel             | HTTPS via proxy          | ❌ No         | ❌ No        | Secure tunneling       |


monolithic and microservices Architecture

controller layer-> service layer->repostiory layer 


client->controller layer->service layer->repostiory layer (db)

controller layer-> layer to write controller is the first entry point of the fastapi application which have the apis that client calls
cl-> takes the requests no business logic and forwards the request to service layer in order to do some processing of business logic
cl-> get the data from the client and forward it to service and whatever service is returning and forward it to the client

service layer-> all the business operations happen in the service layer any modifications or population of the data
sl-> this layer forwards it to repostiory layer and calls the repostiory layer

repostiory layer-> is to talk to the database fetch the data from db and return it to the service layer
service layer-> takes ther response from the repostiory layer and give it to controller layer

even service layer can talk to database and fetch the data but it is not good practice 

src/
app/
│
├── main.py
│
├── api/
│   ├── v1/
│   │   ├── routes/
│   │   │   └── user_controller.py
│   │   └── router.py
│
├── services/
│   └── user_service.py
│
├── repositories/
│   └── user_repository.py
│
├── models/
│   └── user_model.py
│
├── schemas/
│   └── user_schema.py
│
├── db/
│   ├── database.py
│   └── session.py
│
└── core/
    └── config.py


Client
  ↓
Controller (API Route)
  ↓
Service (Business Logic)
  ↓
Repository (Database)
  ↓
Database

why do we need a translator?
computer program is written in high level programming language(humans can understand better) low level programming language(machine can understand better)
machines can only understand 0s and 1s and not high level programming language
translator is a piece of software that converts a high level programming language to binary language which can be understood by machines
types of translator-> compiler and interpreter

compiler-> is a complex piece of software used to convert source code to binary code in one go
c is complied programming language

machine(complier)-> executable code(.exe in windows and .app in macos)

pass the executable code to another machine and compile it to produce the output

sum.c,.exe and sum.o
sum.o->object file 
.exe executable can run on any windows machine
the other machine can just take this executable and run it

interpreter->software program written to translate source code to machine code line by line

machine-> has the soruce code
then copy of source code is sent to other machine
interpreter must be installed in other machine
interpreter translates the code on the fly(run time) line by line
interpreter never generates an executable translate each line of code at run time and generate output on the screen
browser is example for interpreter

python is both interperted and compiled language(hybrid language)
source code(.py)->compiler(bytecode .pyc)->virtual machines(interperter is part of it which generates machine code on the fly and see the output generated)

to see the bytecode use the module py_compile py_compile.compile()


networking concepts
ip address->identifier house address for mail delivery 
http request-> http response<-(public ip address)

domain name system
translates ip address to human readable names so that browser can find the website

ports->numbered channels on a server ranging from 1 to 65535
different apps listen on different ports
standard ports-> 80(web apps),3306(mysql)
every port is unique for every device and every app needs a port 

network segementation 
subnets-> let us divide our network into seperate sections
frontend servers(public facing)->subnet A(ip->10.0.1.x)
application->subnet B(10.0.2.x)
database-> subnet C(10.0.3.x)

routing directs traffic between different routing segments
when the network needs data from the database router will determine the path (gps for network data)

firewalls->security guard that checks every piece of traffic and decides whatever to allow based
on the rules we set 
host firewalls network firewalls

private ip address work inside your own network

network address translation allows multiple devices with private ip address  to share one public ip address when accessing the internet

all the backend servers can reach the internet through one ip address

moving to cloud-> someone else manages the hardware and  increase or decrease our capacity

need -> ip,ports,subnets,routing,firewalls,nat

virtual private cloud-> isolated section of cloud provider's network

internet gateway to connect our public subnets to the internet


microservices Architecture

containers packs everything an application needs

container networks
bridge network->all containers connected to the same bridge network can communicate
with each other using just container names
port mapping
overlay networks->virtual network that spans multiple hosts making containers appear on different servers
as if they were on the same network

kubernetes-> automotes container management
pod-> basic unit group of one or more containers that work closely together in a container per pod
kubernetes services-> stable ip address dns name that will never change

k8 clusters

ingress-> single ingresss can handle all incoming traffic into the cluster and route it to
correct cluster based on the rules we configured


monolithic Architecture-> the application is treated as a single unit
where frontend,backend and database are all part of one codebase and usually one deployment

Characteristics
Single codebase
Single database
Single deployment unit
Components are tightly coupled

Advantages
✔ Simple to develop (good for beginners)
✔ Easy to deploy
✔ Easier debugging
✔ Less infrastructure needed

❌ Disadvantages
❌ Hard to scale specific features
❌ Large codebase becomes hard to maintain
❌ One bug can affect entire app
❌ Slower deployments as app grows


microservices architecture-> breaks the application into small and independent services
Each service:
Has a single responsibility
Runs independently
Communicates via HTTP / REST / gRPC / message queues
Can be deployed independently

Characteristics
Multiple small services
Each service has its own database
Independent deployment
Loosely coupled
Communicate via APIs


Advantages
✔ High scalability
✔ Fault isolation (one service fails, others still work)
✔ Faster deployments
✔ Different technologies per service
✔ Easier for large teams


❌ Disadvantages
❌ Complex architecture
❌ Harder to debug
❌ Network latency
❌ Requires DevOps skills
❌ More infrastructure cost

| Feature         | Monolithic | Microservices           |
| --------------- | ---------- | ----------------------- |
| Codebase        | Single     | Multiple                |
| Deployment      | One unit   | Independent services    |
| Scalability     | Entire app | Per service             |
| Database        | Single     | Per service             |
| Technology      | Same stack | Can vary                |
| Fault isolation | Poor       | Excellent               |
| Complexity      | Low        | High                    |
| Best for        | Small apps | Large, scalable systems |


Transport layer security 
tcp handshake  certificate check key exchange and data transmission

assymmetric encryption(public key,private key)

RSA is a method for session key exchange
BUT nowadays diffie-hellmen is a more comman way of exchanging session key


vertical scaling-> add more resources like ram or upgrade the cpu of the server(very limited)
replicas(better approach)-> to handle a subset of requests

horizontal scaling-> more powerful because it adds redudancy and fault tolerance this elimnates
single point of failure (complicated process)

load balancer->server known as reverse proxy directs incoming requests to the appropirate server

algorithm-> round robin which balance by cycling through our pool of servers 
hashing-> hashing the incoming request id

content delivery networks->network of servers located all around the world

caching-> creating copies of data so that it can be refetched faster in the future

ip address

tcp/ip 
dns-> googledomains

https(application layer protocol)

api paradigms-> rest,graphql,grpc
grpc framework-> used for server-server communication  

protocol buffers vs json

websocktes-> supports bidrectional comunication 

database mangement systems
consistency 
sharding
replication-> leader-follower replication leader-leader replication
CAP theorem->to weigh tradeoffs with replicated design consistency avaliability and partition

message queues->data can be persisted using them and many apps can become decoupled 

RAG

1.fetch relevant information from database
2.when querying the LLM 
3.at that time we give question + context from db
4.use this information to answer the question 


SSL stands for Secure Socket layer protocol that encrypts data that is transmitted between computers
TLS stands for Transport Layer Security newer version of SSL but with best secuirty practices

SSL is depreciated way back 2015
if it is http-> unsecure
https-> 's' being secuirty

handshake-> browser and server engage in an handshake to establish secure connection


client-> client hello -> server
server-> server hello and also sends ssl certificate -> client

git config --global user.email


JWT(JSON web token)
CLIENT access some protective data of the server
SERVER knows clients cannot be trusted and server only gives the data for trustworthy client
1.client sends a request to the server get /login with username and password
2.server creates a jwt token
3.this token is returned to client {token:'token'}
4.client sends a copy of jwt when making a request 
5.server checks for jwt signature
6.server sends a response to client {message:"hello"}


MVC(model view controller)
architectural pattern (govers the whole architecture of the application) design patters are used to solve specify arch problems
mvc divides a software application in 3 parts ->model,view and controller (sepeartion of concerns)

client->server->database
client sends a request to the server and there is a layer at the begining of the server namely blue which interacts with the 
database and fetchs the necessary Data
model cannot fetch the data directly because the red is specialized in talking to the database
now blue will parse the information to red and red interacts with the database and fetchs the necessary data and sends it to 
blue and blue should ideally send the data to client but it has raw data(not in human readable format)
another layer called green specializes in presenting data to the client
blue gives raw data to green and green formats the data(takes the raw data and arrange them in tabular format or applying some styling)
this formatted data is sent to the client this is how mvc works
red: model
green: view
blue: controller
client sends a request to the server then controller takes that request to model then model interacts with database and in the process
may execute some bussiness logic required after getting data from database it passes to the controller
controller now passes the data to view view formats the data this data is sent to the client
model interacts with database and responisble for executing business logic(deals with data)
view is what viewers sees on the screen generates user interface for the user 
controller takes the input(request parameters) also interacts with model and view acts like a middle man between our model and view
in java 
model -> java class
view -> jsp page
controller -> servlet  or servlet filter

high level controller layer
1. routing-> it has a list of routes  url route and http method defined which is triggered by the user and specific data is
present for that particular route
2.request validation layer(middlewares)-> the incoming input request(request body) and wants some of the parameters for processing
it validates the incoming request whether it follows the api contract or not it can directly revert back to the routing layer
we can multiple validation 
this layer sends the request to the controller layer if all the validation checks are done
3. controller layer-> to call the model layer and prepare the response object 
takes the request from routing and middlewares and pass the request to the to the model part and prepare the response object  
of each layer is of seperate directory
routing handles the detials of incoming routes and http methods which route and http method is allocated to which controller and 
middleware
middleware handles validation 

high level model layer
request it brought to the service layer
1.service layer-> any business logic is going to reside inside this layer
any business logic should never reside inside the controller layer
2.repository layer-> will never contain the business logic it will contain interfaces and methods using which you will fetch the data
repostiory layer will technically communicate with the databases
3. high level model layer-> defines the programming interface of the databases (inside the databases the kind of data being stored)
(storing email password user_id username address of user ) like userclass stored user stored in the database
how the data will be stored in db -> model layer


config folder-> any kind of configurations like environment variables or any kind of configurable data 
utils folder-> helper methods that is reusable in multiple parts of the codebase like converting your time into a particular format
this function can be reuse in multiple places in the codebase

client (react/nextjs project)-> routing layer (this maps the http method and url routes that are supported by our app get/ping)
routing layer-> middleware(it validates the incoming request details like request body to create a product you would need like name,city,detials of product)
like mandatory details of the product
middleware-> controller layer(this layer forwards the request to the server layer takes repsone from service layer and prepare http response object)
keep this in mind-> no business logic controller should be thin there should be any bloating or too much logic should not be there
in controller 

controller layer-> service layer(all the business logic goes inside this layer) alogrithm to match the user and the cab driver
so all this goes inside the controller layer 
keep this in mind-> each layer is a folder and every folder will have multiple files then forwards the request for executing business logic
and needs data
service layer-> repoistory layer(this layer is responible for providing data to service layer)
maybe same type of data might be required in multiple services like service matching users and riders or service mantaining details of the user
one service shows the rider's history so multiple services needs the same kind of data 
not requeired to implment the same kind everywhere one method in repo layer and everyone will call that method

database-> actual data exists here

repository layer->models(gives blueprint about how the data should in the database they mainly have classes)
(these classes represnets how the data will look in the database)

optional folders
config folder-> this contains any configuration example-> env variables
utils folder-> any reusable helper methods goes here 

model represnets how the data looks in the database
repoistory contains the logic to retrieve the data from the database 
connect to the database servers there is tcp connection setup between your codebase and database then query the data
some languages/frameworks repo layer directly connects to the database
model has one responsibility to determine how the data looks in the database

database returns data in the form of json
actual classes is present inside the models 
but in some languages/frameworks repo layer cannot communicate directly to the database and instead the logic for db connection exists within 
the models

raw querys can be written in the repo layer use case of migration of services and representing the data and fetching of the data
make the code as modular as possible 


JWT
It is a widely used mechanism to secure the authentication to secure your endpoints
this is nothing but a token having three parts
and each part is sepearted by dots
firstpart.secondpart.thirdpart(example)

firstpart -> header(alogrithm used to create the necessary token using HS256)
this does not change and remains the same

secondpart-> payload(user's information) like user_id,user_name,token_issued,token_expiration
expiration issue iat: issued_at time is usually written in long

jwt expires(the token is not valid anymore)

signature->secrets to store secret data like env variables
the secret is used to create this token 
you need a 
header(algo used to create the jwt token)
payload(user's information)
secret key(this is hidden)

1.creating a jwt token
base64url is used to convert any special characters like "",.,/,'' etc into a basic string
simple encoding
and can be easily decoded

encoded header.encoded payload.secretkey(adding a dot and concatenating them )
then secret key is taken and alogrithm like HMACSHA-256 is implmeneted
and the input for this secretkey and concatenation of header and payload
and finally an encoded signature is formed the algorithm splits 
"." concat-> jwt token

jwt is basically used for encoding

2.validating a jwt 

client-> server(sends username and password for /login endpoint)
this validates credentials and raise a token generation request
send jwt token as a response
use access token to make a request 
(you give me this token and i need to use this service)

token-> first part and second part and third part will be seperated
takes the first and second parts secret key being stored in the server
secret key will be avaliable at the time for token verification 
the same algo used to make another encoded signature
the new encoded signature and the previous signature is compared to check for equality
if they are equal they are valid if not invalid

if access token is valid fulfill the request(server checks for validating the token)

jwt is basically used to prove this token is generated by you 


RAG
main motivation of rag is connecting llms to external data 

retrieval augmented generation(rag)
question-> (database<-documents)[indexing]->(relevant document)[retrieval]->(context window)[generation]->answer

query translation
routing
query construction
indexing
retrieval
filtering
generation(active rag)

indexing
1.document loading: question->retriever retriever<-load documents   retriever->relevant docuemnts 
representation of similarity is typically done using numerical or text representation because it is easy to compare with vectors
statistical and machine learned representations

statistical->bag of words->representation(sparse)->search(bm25)
machine learned->embedding->dense->knn,hnsw

loading,splitting and embedding
embedding models have small context windows these docuemnts are split and each document is compressed into a vector
vector captures the semantic meaning of the document itself

a simple rag -> prepare the data, query for retrieval data and craft the response

data soruce

original text->text splitter->chunks of text->embeddings

embeddings are representation of text to capture their meaning literally list of numbers in python


python decorators

it helps you add extra behaviour to a function without changing the function's code
decorator is a function that takes another function as input without changing the function's code

we define decorator first and then apply it with @decorator_name above the function

def changecase(func):
  def inner():
    return func().upper()
  return inner

@changecase
def function():
  return "hello sally"

print(function())


By placing @changecase directly above the function definition, the function myfunction is being "decorated" with the changecase function.

The function changecase is the decorator.

The function myfunction is the function that gets decorated.

Multiple Decorator Calls
A decorator can be called multiple times. Just place the decorator above the function you want to decorate.


def changecase(func):
  def inner(x):
      return func(x).upper()
  
  return inner

@changecase
def function(name):
    return "hello"+name
  
print(function("sally"))


args-> a function that takes any number of  positional arguments

def my_function(*args):
  print(type(args))
  print(args[0])
  print(args[1])
  print(args[2])

my_function("john","suresh","john")


kwargs-> a function that accepts any number of keyword arguments

"type hints" or annotations are special syntax that allows declaring a type of variable 
By declaring types for your variables, editors and tools can give you better support.


def get_names(first_name:str,last_name:str):
  full_name=first_name.title()+" "+last_name.title()
  return full_name

print(get_names("john","doe"))

codes:
def changecase(func):
    def inner(x):
        return func(x).upper()
    return inner

@changecase
def function(name):
    return "hello "+name

# print(function("sally"))

def function1(*args):
    print("type",type(args))
    print("first augement",args[0])
    print("second augement",args[1])
    print("thrid augement",args[2])

# function1("tobias","john","duke")

def my_function(greeting,*names):
    for name in names:
        print(greeting,name)

# my_function("Hello","sally","john","milton","kumar")

def func1(**var):
    print("type",type(var))
    print("name ",var["name"])
    print("age ",var["age"])
    print("data ",var)
    
# func1(name='John',age="25",city="Hyderabad")

def get_names(first_name:str,last_name:str):
    full_name=first_name.title()+" "+last_name.title()
    return full_name
    
# print(get_names("john","doe"))

def get_age_with_name(name:str,age:int):
    name_with_age=name+" is "+str(age)+" years old"
    return name_with_age

print(get_age_with_name("john",23))




Design Patterns and ORM
CREATIONAL->singleton,prototype,builder and factory 
creational patterns are how objects are created
STRUCUTURAL->facade,proxy
sturctural patterns are how objects related to each other
BEHAVIOURAL->iterator,observer,mediator,state
behavioural patterns are how objects communicate with each other

CREATIONAL
Singleton-> type of object that can only be instantiated once
Prototype-> fancy word of clone alternative way to implement inheritance
but instead of inheriting functionality from a class it comes from an object
that is already been created
Builder->we create the object step by step using methods rather than the Constructor
delegate the building logic to an entirely different class (method chaninig)
Factory-> instead of using new keyword to instantiate an object we can use a function 
or method 

STRUCUTURAL
Facade->face of the building it is bascially a simplified API to hide your low level details
in your codebase almost every packages that is installed in javascript is type of facade in a way
Proxy->fancy word for substitute you can replace a target object with a proxy 
case study to do that -> Reactivity system in vue.js 
a proxy takes  the original object as the first argument then a handler as second argument inside
which methods can be override 
proxies are also commonly used that when you have a very large object that would be expensive to 
duplicate in memory

BEHAVIOURAL
Iterator->allows you to traverse through a collection of objects it is a pull based system
Observer-> it is a push based system allows many objects to subscribe to any events that 
are broadcast by another object like a one-to-many-relationship it is like a loop that
unfolds over the dimension of time
Mediator->middleman or broker like objects have to communicate with each in case of many-to-many
like in express.js request->middleware->response middleware provides seperation of concerns and 
code duplication
State->an object behaves differently in a finite number of states like during coding switch statements
(switch hell-> code doesn't scale really well) idea is realted to state machines and libraries like
xstate to make an object's behaviour predictable based on the underlying state   

ORM(object realtional mapping)
technique that bridges the gap between object oriented programming languages and databases 

How it works: An ORM framework acts as an abstraction layer. Developers define how their code objects (e.g., a User class) map to database tables (e.g., a Users table) using metadata, configuration files, or annotations. The ORM then automatically generates the necessary SQL queries to perform database operations (Create, Read, Update, Delete - CRUD), so developers can interact with data using their familiar programming language syntax instead of writing raw SQL.
Key Benefits:
Increased Productivity: Automates repetitive data-access code (boilerplate code), allowing developers to focus on business logic.
Abstraction: Hides the underlying database details, making it easier to switch between different database systems with minimal code changes.
Improved Security: ORMs typically use parameterized queries, which helps prevent SQL injection attacks

ORM and Design Patterns: The Connection
ORMs are software tools and, as complex systems, they are built using various design patterns to achieve their functionality. Furthermore, specific design patterns describe different strategies for implementing the ORM concept itself. 
Key patterns used in the context of ORM, as described by Martin Fowler in Patterns of Enterprise Application Architecture, include:
Active Record: A pattern where an object wraps a database row and the object itself contains the data access methods (like save() or find()). This is a simple and intuitive approach, used by frameworks like Ruby on Rails' ActiveRecord.
Data Mapper: This pattern creates a clear separation between the in-memory objects (business logic) and the database persistence logic. A separate "mapper" class or layer is responsible for transferring data between the two, which makes the domain objects persistence-agnostic and easier to test. This is used by frameworks such as Hibernate and SQLAlchemy.
Unit of Work: This pattern maintains a list of objects affected by a business transaction and coordinates the writing of changes to the database as a single, consistent unit of work, often at the end of a transaction.
Data Access Object (DAO): A pattern used to abstract the data access logic to a separate, lightweight interface, which can be a layer within a larger ORM implementation


- 
+ # Use official Python runtime as base image
+ FROM python:3.11-slim
+ 
+ # Set working directory in container
+ WORKDIR /app
+ 
+ # Copy requirements file
+ COPY requirements.txt .
+ 
+ # Install Python dependencies
+ RUN pip install --no-cache-dir -r requirements.txt
+ 
+ # Copy application code
+ COPY main.py .
+ 
+ # Expose port 8000
+ EXPOSE 8000
+ 
+ # Command to run the application
+ CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
+ 


API AUTHENTICATION
it is a technique used to verify the identity of client or user trying to access an api
without authentication it could lead to data leaks breaches and unauthorized use of services
primary benefit-> ensure security it ensures that only authorized clients can access the apis
reducing the risk of malicious attacks data breaches or unauthorized use of resources/sensitive
data
it allows api provides to control access   based on the user's identity
different cleints have different permissions enusring users can access data or services they are
authroized for
Monitor usage patterns which can apply rate limit or throttle access to ensure api isn't overwhelmed 
by too many requests  from a single source
http based authentication-> simpliest form of authenication where client sends username or password 
at the http header encoded in base64 not very secure since credentials are sent with every request which
are not hashed or encrypted by default making this method insecure   
api key authenication-> client sends an unique api key that acts as their identifier when making api requests
key is issues by the api provider   to client enabling to montior usage and control access
limited control function simple to password    
Jwt-> it is a compact stateless mechanism for api authenication  
when a user logs onto a application the api server creates a digitally signed and encrypted jwt
that includes the user's identity then client includes the jwt in every susbquent request 
which the server deserializes and validates 
the user data is not stored on the server's side which improves scalability
jwt authenication is popular because it allows the server to issues tokens that
client can use to autehnicate themselves for future request
the token contains info about user and sign it can't be tempered with
stateless does not store session data
Oauth->more secure allows users to autehnicate via third party service like google or facebook
without having to share their credentials with api itself
Oauth2->access tokens that can expired or revoked providing more granular control
oauth2.0->
AUTHENTICATION-> who are you?
AUTHORIZATION-> what are allowed to do?
login to a website-> authenication and verifies identity
determines access-> authorization

FOR GITHUB SSO 

GitHub Client ID
Ov23lim6OGyn4mV4vL25
Github Client Secrets
374db31f2fbe30de8c85f66570e28dd9f029bfde



Authentication Object Types
Tokens, Biometrics, Single Sign On  and Passwords 

Single Sign on vs Oauth
when we do sign in google or sign in facebook it it open authorization->oauth2
when we are able to access gmail,google drive,youtube using a single login-> sso

the main difference is oauth2.0->we are authorizing a third party to access some of our data(photos or reading a calander)
sso->simplifying login bascially one login for multiple services in corporate 

authenication is the process of checking if someone is who they say they are
user->enter email,password->(does user exist)backend->welcome to website(yes) or go away(no)
authenication in simple words mean it decides if you are allowed entry or not
it is the backend server that verifies the server's credentials to make sure you are trusted user before granting you access to 
website or application 


authorization is the process of determining what actions or parts of a website or app you're allowed to access after you've been
authenicated 
backbone of identity and access management
backend acts like a rule enforcer
once authenicated the server checks your assigned rules permissions or access-levels
then determines what website or app you are allowed to visit and what actions you can perform

authenication(confirms users are who they say they are)
authorization(gives users permissions to access a resource)

different authenication methods (username and password,token based auth,single-sign-on,multi-factor auth and more)


diffrenet types of authorization models
rbac(role based access control)->grants access based on predefined roles employees can access only what they need to do with their jobs nothing more
abac(attribute based access control)->granular approach granting access based on user's attributes like location,device or security clearance
rebac(relationship based access control)->relationship between users and resources a project owner may have full access while a colleague has
view only permissions
mac(mandatory access control)->commonly used by governmenet agencies strictly limiting access based on classification levels and security labels 
dac(discretionary access control)->allows resources owners to control who has access offering more flexibility but requiring careful oversight


to pick the right  authorization model
security requirements
user experience
Complexity
scalability



optical character recongition(ocr)
ocr converts hand written text into machine-readable text for editing searching or data extraction from images or scanned documents 
OCR has come a long way to automate  complex documents both in terms of speed an aaccuracy 
meaning formatted information can retain it's sturcture after being scanned 

it idenitifies the area of text
it figures out the lines of text,spacing between words and all sorts of document elements.
and onc loaded to the characters they're rendered to a high contrast called a bitmap
and from there they can be processed by any number of algorithms
the most common alogrithm is pattern recongition
pattern recongition involves 
training the model with a very large set of characters
comparing the identified character and finding the closest matching one   

another common alogirthm is known as feature analysis 
it relies on characterisitcs of each individual character like how many lines it has,whether is has curved lines or if any of those 
lines intersect with each other
it is more rule based and requires a deeper level of understanding of those characters 

nowadays, 
ocr can find and read a license plate even when it's travelling on a vehicle under a toll bridge like 65 miles per hour perhaps 
even faster ocr combined with ai is a winning combination 

ocr involves detection of text content on images and translation of those images into encoded text that a computer can understand easily 
it is acheived for computers it is a series of dots or pixels
image is first scanned text graphics and elements are converted into bitmap(matrix with black and white dots) 
image is then preprocessed where brightness and contrast are enhanced to improve the accuracy of process 
image is split into zones identifying areas of interest where the images and text are this helps in curve extraction process
the areas containing the text can now be broken down into further lines or characters
now the ocr engine or software is able to match the characters through comparison and various ai techinques 
the final result is the text in the image that we're given
not 100% accurate
error correction can be acheived thorugh nlp or dictionary
application
ocr is used in airports to automate the process passport recongition,extraction from information 
detection and recongition of car number plates

how does ocr acutally work?
load an image
preprocess it(for handwritten text)
send it to tesseract ocr engine  with right configuration

configuration of ocr engine

config="--oem 1 --psm 8"
--oem =>ocr engine mode
1 => neural networks(lstm)
8 => single word   
--psm =>page segementation mode



example 
# # import cv2
# # # import numpy as np
# # import pytesseract
# #
# # pytesseract.pytesseract.tesseract_cmd="/opt/homebrew/bin/tesseract"
# #
# # #core functionality of ocr
# # img=cv2.imread("image copy.jpg")
# #
# # def ocr_core(img):
# #     text=pytesseract.image_to_string(img)
# #     return text
# # #TO GRAYSCALE THE IMAGE
# # def img_to_gray(img):
# #     return cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
# #
# # #TO REMOVE THE NOISE TO MAKE IT MORE SHARP
# # def remove_noise(img):
# #     return cv2.medianBlur(img,5)
# #
# # #thresholding if pixel value above threshold it is black or white and it is below the threshold it is some
# # #other colour
# # def threshodling(img):
# #     return cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]
# #
# #
# # img=img_to_gray(img)
# # img=threshodling(img)
# # img=remove_noise(img)
# #
# # print(ocr_core(img))
# #
# #
# #
# # import pytesseract
# # from PIL import Image
# # pytesseract.pytesseract.tesseract_cmd="/opt/homebrew/bin/tesseract"
# # img=Image.open("image.jpg")
# # text=pytesseract.image_to_string(img)
#
# # print(text)
# import pytesseract
# import cv2
# from PIL import Image
# pytesseract.pytesseract.tesseract_cmd="/opt/homebrew/bin/tesseract"
# img=cv2.imread("handwritten.jpg")
#
# def ocr_core(img):
#     config="--oem 1 --psm 8"
#     text=pytesseract.image_to_string(img,config=config)
#     return text
#
# def gray_scale(img):
#     grey=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
#     return grey
#
# def remove_noise(img):
#     return cv2.medianBlur(img,3)
#
# def thresholding(img):
#     return cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]
#
# img=gray_scale(img)
# img=thresholding(img)
# img=remove_noise(img)
#
# print(ocr_core(img))

# from gtts import gTTS
# language="en"
# text="""
# Life is a rollercoaster, full of ups and downs.
# Sometimes you have to bite the bullet and face challenges head-on.
# Every cloud has a silver lining, and good things come to those who wait.
# I try to keep my eyes on the ball and not let small setbacks get under my skin.
# At the end of the day, it's all water under the bridge, and tomorrow is a new day.
#
#
# """
# speech=gTTS(text=text,lang=language,slow=False,tld="co.in")
# speech.save("test.mp3")
# #
import whisper

model=whisper.load_model("base")

res=model.transcribe("test.mp3")
print(res["text"])

ROLE BASED ACCESS CONTROL 
it is about restricting access based on user roles
for example 
admin-> access for everything
user-> limited access
guest-> very limited access 
In fastapi we can implement this using dependencies 